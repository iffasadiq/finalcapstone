{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iffasadiq/finalcapstone/blob/main/Dynamic_Pricing_for_Urban_Parking_Lots_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Dynamic Pricing for Urban Parking Lots - Capstone Project\n",
        "Summer Analytics 2025\n",
        "\n",
        "This notebook implements a dynamic pricing engine for urban parking lots based on real-time data.\n",
        "It includes:\n",
        "1. Data loading, exploration, and preprocessing.\n",
        "2. Implementation of three pricing models:\n",
        "   - Model 1: Baseline Linear Model\n",
        "   - Model 2: Demand-Based Price Function\n",
        "   - Model 3: Competitive Pricing Model (Optional)\n",
        "3. Conceptual integration with Pathway for real-time simulation.\n",
        "4. Real-time visualizations using Bokeh (demonstrated with historical data).\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "# For Bokeh visualizations\n",
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import ColumnDataSource, DatetimeTickFormatter\n",
        "from bokeh.palettes import Category10\n",
        "from bokeh.layouts import column # For arranging multiple plots\n",
        "\n",
        "# Ensure Bokeh outputs to the notebook\n",
        "output_notebook()\n",
        "\n",
        "# --- Global Constants ---\n",
        "BASE_PRICE = 10.0 # Starting base price for all parking lots\n",
        "MIN_PRICE_GLOBAL = BASE_PRICE * 0.5 # Minimum allowed price (0.5x base)\n",
        "MAX_PRICE_GLOBAL = BASE_PRICE * 2.0 # Maximum allowed price (2x base)\n",
        "\n",
        "# Model 1 Coefficients\n",
        "ALPHA_MODEL1 = 5.0 # Sensitivity of price to occupancy rate in Model 1\n",
        "\n",
        "# Model 2 Demand Function Coefficients (tuned for illustrative purposes)\n",
        "# These coefficients should ideally be determined through regression or domain expertise.\n",
        "# Positive alpha for OccupancyRate, QueueLength, IsSpecialDay, VehicleTypeWeight\n",
        
        "ALPHA_OCCUPANCY = 0.5      \n",
        "ALPHA_QUEUELENGTH = 0.3    \n",
        "ALPHA_TRAFFIC = 0.2        \n",
        "ALPHA_SPECIALDAY = 1.0     \n",
        "ALPHA_VEHICLETYPE = 0.1    \n",
        "\n",
        "# Model 2 Price Adjustment Coefficient\n",
        "LAMBDA_MODEL2 = 0.5 # Sensitivity of price to normalized demand\n",
        "\n",
        "# Model 3 Competitive Pricing Constants\n",
        "COMPETITOR_DISTANCE_THRESHOLD_KM = 1.0 # Distance threshold to consider a lot a competitor\n",
        "ETA_COMPETITIVE = 0.1 # Sensitivity of price to competitive advantage\n",
        "\n",
        "\n",
        "# --- Milestone 1: Data Understanding, Exploration, and Preprocessing ---\n",
        "\n",
        "print(\"--- Milestone 1: Data Understanding, Exploration, and Preprocessing ---\")\n",
        "\n",
        "# 1. Load the dataset\n",
        "# Using 'dataset.csv' as per the last uploaded file.\n",
        "DATASET_FILENAME = 'dataset.csv'\n",
        "print(f\"Loading the dataset '{DATASET_FILENAME}'...\")\n",
        "try:\n",
        "    df = pd.read_csv(DATASET_FILENAME)\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: '{DATASET_FILENAME}' not found. Please ensure the file is in the correct directory (e.g., uploaded to Colab).\")\n",
        "# 2. Display basic information and descriptive statistics\n",
        "print(\"\\n--- Initial Data Overview ---\")\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 3. Combine date and time columns into a single datetime object and sort\n",
        "df['Timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'])\n",
        "# Sort by timestamp to simulate chronological data flow for pricing models\n",
        "df = df.sort_values(by='Timestamp').reset_index(drop=True)\n",
        "print(\"\\n'Timestamp' column created and dataset sorted by time.\")\n",
        "print(df[['LastUpdatedDate', 'LastUpdatedTime', 'Timestamp']].head())\n",
        "\n",
        "# 4. Calculate Occupancy Rate\n",
        "df['OccupancyRate'] = df['Occupancy'] / df['Capacity']\n",
        "# Handle potential division by zero or infinite values if Capacity could be 0\n",
        "df['OccupancyRate'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df['OccupancyRate'].fillna(0, inplace=True) # Fill NaN occupancy rates with 0\n",
        "df['OccupancyRate'] = df['OccupancyRate'].clip(0, 1) # Ensure occupancy rate is between 0 and 1\n",
        "print(\"\\n'OccupancyRate' column added and clipped between 0 and 1.\")\n",
        "print(df[['Occupancy', 'Capacity', 'OccupancyRate']].head())\n",
        "\n",
        "# 5. Encode categorical features\n",
        "# Define weights for VehicleType. These are assumptions and can be refined.\n",
        "vehicle_type_weights = {\n",
        "    'car': 1.0,\n",
        "    'bike': 0.5, # Bikes take less space, might have lower demand weight\n",
        "    'truck': 1.5 # Trucks take more space, higher demand weight or special pricing\n",
        "}\n",
        "df['VehicleTypeWeight'] = df['VehicleType'].map(vehicle_type_weights)\n",
        "# Handle potential NaN if a vehicle type not in map appears\n",
        "df['VehicleTypeWeight'].fillna(1.0, inplace=True) # Default to car weight if unknown type\n",
        "print(\"\\n'VehicleTypeWeight' column added based on mapping.\")\n",
        "print(df[['VehicleType', 'VehicleTypeWeight']].head())\n",
        "\n",
        "# Ordinal encoding for TrafficConditionNearby\n",
        "traffic_mapping = {\n",
        "    'low': 0,\n",
        "    'average': 1,\n",
        "    'high': 2\n",
        "}\n",
        "df['TrafficConditionEncoded'] = df['TrafficConditionNearby'].map(traffic_mapping)\n",
        "# Handle potential NaN if an unknown traffic condition appears\n",
        "df['TrafficConditionEncoded'].fillna(0, inplace=True) # Default to 'low' traffic if unknown\n",
        "print(\"\\n'TrafficConditionEncoded' column added based on ordinal mapping.\")\n",
        "print(df[['TrafficConditionNearby', 'TrafficConditionEncoded']].head())\n",
        "\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(\"\\nDataset after preprocessing (first 5 rows with new columns):\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# --- Milestone 2: Model 1: Baseline Linear Model Implementation ---\n",
        "\n",
        "print(\"\\n\\n--- Milestone 2: Implementing Model 1: Baseline Linear Model ---\")\n",
        "\n",
        "# Initialize a dictionary to store current prices for each parking lot\n",
        "# This simulates the state of prices in a real-time system.\n",
        "current_prices_model1 = {lot_id: BASE_PRICE for lot_id in df['SystemCodeNumber'].unique()}\n",
        "\n",
        "# Prepare a list to store pricing results for analysis and visualization\n",
        "model1_pricing_results = []\n",
        "\n",
        "# Simulate price updates over time, iterating through the sorted dataframe\n",
        "# In a real-time Pathway system, this logic would apply to incoming data streams.\n",
        "for index, row in df.iterrows():\n",
        "    lot_id = row['SystemCodeNumber']\n",
        "    occupancy_rate = row['OccupancyRate']\n",
        "    current_time = row['Timestamp']\n",
        "\n",
        "    # Get the previous price for this lot from the current state\n",
        "    prev_price = current_prices_model1[lot_id]\n",
        "\n",
        "    # Calculate the next price based on Model 1 logic: Pricet+1 = Pricet + α · OccupancyRate\n",
        "    next_price = prev_price + ALPHA_MODEL1 * occupancy_rate\n",
        "\n",
        "    # Apply global price bounds to ensure smoothness and realism\n",
        "    next_price = max(MIN_PRICE_GLOBAL, min(MAX_PRICE_GLOBAL, next_price))\n",
        "\n",
        "    # Update the current price for the lot in the state dictionary\n",
        "    current_prices_model1[lot_id] = next_price\n",
        "\n",
        "    # Store the results for this timestamp and lot\n",
        "    model1_pricing_results.append({\n",
        "        'Timestamp': current_time,\n",
        "        'SystemCodeNumber': lot_id,\n",
        "        'CurrentOccupancyRate': occupancy_rate,\n",
        "        'Model1_Price': next_price\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for easier analysis\n",
        "model1_df = pd.DataFrame(model1_pricing_results)\n",
        "print(\"\\nModel 1 simulation complete.\")\n",
        "print(\"Sample of Model 1 pricing results:\")\n",
        "print(model1_df.head())\n",
        "\n",
        "# Merge Model 1 prices back to the main DataFrame for comprehensive analysis later\n",
        "df = df.merge(model1_df[['Timestamp', 'SystemCodeNumber', 'Model1_Price']],\n",
        "              on=['Timestamp', 'SystemCodeNumber'],\n",
        "              how='left')\n",
        "print(\"\\nModel 1 prices merged back to main DataFrame.\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# --- Milestone 3: Model 2: Demand-Based Price Function Implementation ---\n",
        "\n",
        "print(\"\\n\\n--- Milestone 3: Implementing Model 2: Demand-Based Price Function ---\")\n",
        "\n",
        "# 1. Calculate Raw Demand for all records\n",
        "# Demand = α1·OccupancyRate + α2·QueueLength + α3·Traffic + α4·IsSpecialDay + α5·VehicleTypeWeight\n",
        "# Note: We use positive ALPHA_TRAFFIC assuming higher traffic means more people looking for parking.\n",
        "df['RawDemand'] = (\n",
        "    ALPHA_OCCUPANCY * df['OccupancyRate'] +\n",
        "    ALPHA_QUEUELENGTH * df['QueueLength'] +\n",
        "    ALPHA_TRAFFIC * df['TrafficConditionEncoded'] +\n",
        "    ALPHA_SPECIALDAY * df['IsSpecialDay'] +\n",
        "    ALPHA_VEHICLETYPE * df['VehicleTypeWeight']\n",
        ")\n",
        "print(\"\\n'RawDemand' calculated for all records based on defined coefficients.\")\n",
        "print(df[['OccupancyRate', 'QueueLength', 'TrafficConditionEncoded', 'IsSpecialDay', 'VehicleTypeWeight', 'RawDemand']].head())\n",
        "\n",
        "# 2. Normalize Demand\n",
        "# Normalize based on the full range of 'RawDemand' across the entire dataset.\n",
        "# This ensures demand is scaled consistently to a [0, 1] range.\n",
        "min_demand = df['RawDemand'].min()\n",
        "max_demand = df['RawDemand'].max()\n",
        "\n",
        "# Handle case where min_demand == max_demand to prevent division by zero\n",
        "if max_demand == min_demand:\n",
        "    df['NormalizedDemand'] = 0.0 # All demands are the same, so normalized demand is 0\n",
        "else:\n",
        "    df['NormalizedDemand'] = (df['RawDemand'] - min_demand) / (max_demand - min_demand)\n",
        "\n",
        "print(\"\\n'NormalizedDemand' calculated and scaled to [0, 1].\")\n",
        "print(df[['RawDemand', 'NormalizedDemand']].head())\n",
        "\n",
        "# 3. Simulate price updates for Model 2 using the normalized demand\n",
        "# Pricet = BasePrice · (1 + λ · NormalizedDemand)\n",
        "model2_pricing_results = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    normalized_demand = row['NormalizedDemand']\n",
        "    current_time = row['Timestamp']\n",
        "    lot_id = row['SystemCodeNumber']\n",
        "\n",
        "    # Calculate price based on Model 2 logic\n",
        "    model2_price = BASE_PRICE * (1 + LAMBDA_MODEL2 * normalized_demand)\n",
        "\n",
        "    # Apply global price bounds\n",
        "    model2_price = max(MIN_PRICE_GLOBAL, min(MAX_PRICE_GLOBAL, model2_price))\n",
        "\n",
        "    # Store results\n",
        "    model2_pricing_results.append({\n",
        "        'Timestamp': current_time,\n",
        "        'SystemCodeNumber': lot_id,\n",
        "        'NormalizedDemand': normalized_demand,\n",
        "        'Model2_Price': model2_price\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "model2_df_results = pd.DataFrame(model2_pricing_results)\n",
        "print(\"\\nModel 2 simulation complete.\")\n",
        "print(\"Sample of Model 2 pricing results:\")\n",
        "print(model2_df_results.head())\n",
        "\n",
        "# Merge Model 2 prices back to the main DataFrame\n",
        "df = df.merge(model2_df_results[['Timestamp', 'SystemCodeNumber', 'Model2_Price']],\n",
        "              on=['Timestamp', 'SystemCodeNumber'],\n",
        "              how='left')\n",
        "print(\"\\nModel 2 prices merged back to main DataFrame.\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# --- Milestone 4: Model 3 (Optional): Competitive Pricing Model Implementation ---\n",
        "\n",
        "print(\"\\n\\n--- Milestone 4: Implementing Model 3 (Optional): Competitive Pricing Model ---\")\n",
        "\n",
        "# 1. Calculate geographic proximity of nearby parking spaces\n",
        "# Get unique parking lot locations\n",
        "parking_lots_geo = df[['SystemCodeNumber', 'Latitude', 'Longitude']].drop_duplicates().set_index('SystemCodeNumber')\n",
        "\n",
        "# Haversine distance function (in km)\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371 # Earth radius in kilometers\n",
        "\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# Calculate distances between all unique parking lots\n",
        "# This creates a distance matrix which is computationally intensive for large number of lots,\n",
        "# but feasible for 14 lots.\n",
        "lot_ids = parking_lots_geo.index\n",
        "distances = pd.DataFrame(index=lot_ids, columns=lot_ids, dtype=float)\n",
        "\n",
        "for i in range(len(lot_ids)):\n",
        "    for j in range(i, len(lot_ids)):\n",
        "        lot1 = lot_ids[i]\n",
        "        lot2 = lot_ids[j]\n",
        "        lat1, lon1 = parking_lots_geo.loc[lot1]['Latitude'], parking_lots_geo.loc[lot1]['Longitude']\n",
        "        lat2, lon2 = parking_lots_geo.loc[lot2]['Latitude'], parking_lots_geo.loc[lot2]['Longitude']\n",
        "\n",
        "        dist = haversine(lat1, lon1, lat2, lon2)\n",
        "        distances.loc[lot1, lot2] = dist\n",
        "        distances.loc[lot2, lot1] = dist # Symmetric matrix\n",
        "\n",
        "# Fill diagonal with 0 (distance to self is 0)\n",
        "np.fill_diagonal(distances.values, 0)\n",
        "\n",
        "print(\"\\nDistance matrix between parking lots calculated (in km):\")\n",
        "print(distances.head())\n",
        "\n",
        "\n",
        "# 2. Determine competitor parking prices and factor them into pricing.\n",
        "model3_pricing_results = []\n",
        "\n",
        "# Initialize a dictionary to store the *latest calculated price* for each lot.\n",
        "# This will act as the \"current\" price that competitors see.\n",
        "# In a real-time system, this would be a state table managed by Pathway.\n",
        "current_lot_prices_state = {lot_id: BASE_PRICE for lot_id in df['SystemCodeNumber'].unique()}\n",
        "\n",
        "# Group the DataFrame by Timestamp to process all lots for a given time step\n",
        "# This ensures that when calculating competitor prices for a given timestamp,\n",
        "# we use the prices of competitors that were also calculated for that same timestamp.\n",
        "for timestamp, time_group_df in df.groupby('Timestamp'):\n",
        "    # Create a temporary dictionary to store prices calculated for this specific timestamp\n",
        "    # This prevents using prices from *future* timestamps as competitor prices.\n",
        "    prices_this_timestamp = {}\n",
        "\n",
        "    for index, row in time_group_df.iterrows():\n",
        "        lot_id = row['SystemCodeNumber']\n",
        "        normalized_demand = row['NormalizedDemand'] # Use the normalized demand from Model 2\n",
        "\n",
        "        # Get nearby competitors for the current lot based on the distance threshold\n",
        "        nearby_competitors = distances.loc[lot_id][distances.loc[lot_id] <= COMPETITOR_DISTANCE_THRESHOLD_KM].index.tolist()\n",
        "        if lot_id in nearby_competitors:\n",
        "            nearby_competitors.remove(lot_id) # Remove self from competitors list\n",
        "\n",
        "        # Get competitor prices from the 'current_lot_prices_state'\n",
        "        # This simulates using the most recently available prices of competitors.\n",
        "        competitor_prices = [current_lot_prices_state[comp] for comp in nearby_competitors if comp in current_lot_prices_state]\n",
        "\n",
        "        # Calculate average competitor price (default to BASE_PRICE if no nearby competitors)\n",
        "        avg_competitor_price = np.mean(competitor_prices) if competitor_prices else BASE_PRICE\n",
        "\n",
        "        # Competitive Logic: Calculate competitive advantage factor\n",
        "        # If avg_competitor_price is higher than my current base price, it's an advantage.\n",
        "        # If it's lower, it's a disadvantage.\n",
        "        competitive_advantage_factor = 0.0\n",
        "        if avg_competitor_price > 0: # Avoid division by zero if prices are somehow 0\n",
        "            # Calculate relative difference from my base price.\n",
        "            # A positive value means competitors are generally more expensive.\n",
        "            relative_price_diff = (avg_competitor_price - BASE_PRICE) / BASE_PRICE\n",
        "            competitive_advantage_factor = ETA_COMPETITIVE * relative_price_diff\n",
        "\n",
        "        # Model 3 Price Calculation: Combine Model 2's logic with competitive factor\n",
        "        # Pricet = BasePrice · (1 + λ · NormalizedDemand + η · CompetitiveAdvantage)\n",
        "        model3_price = BASE_PRICE * (1 + LAMBDA_MODEL2 * normalized_demand + competitive_advantage_factor)\n",
        "\n",
        "        # Apply global price bounds\n",
        "        model3_price = max(MIN_PRICE_GLOBAL, min(MAX_PRICE_GLOBAL, model3_price))\n",
        "\n",
        "        # Store the calculated price for this lot for the *current* timestamp\n",
        "        prices_this_timestamp[lot_id] = model3_price\n",
        "\n",
        "        # Store results for this record\n",
        "        model3_pricing_results.append({\n",
        "            'Timestamp': timestamp,\n",
        "            'SystemCodeNumber': lot_id,\n",
        "            'NormalizedDemand': normalized_demand,\n",
        "            'AvgCompetitorPrice': avg_competitor_price,\n",
        "            'CompetitiveAdvantageFactor': competitive_advantage_factor,\n",
        "            'Model3_Price': model3_price\n",
        "        })\n",
        "\n",
        "    # After processing all lots for the current timestamp, update the global state\n",
        "    # with the newly calculated prices. This ensures the next timestamp group\n",
        "    # uses the most up-to-date competitor prices.\n",
        "    for lot_id, price in prices_this_timestamp.items():\n",
        "        current_lot_prices_state[lot_id] = price\n",
        "\n",
        "\n",
        "# Convert Model 3 results to a DataFrame\n",
        "model3_df_results = pd.DataFrame(model3_pricing_results)\n",
        "print(\"\\nModel 3 simulation complete.\")\n",
        "print(\"Sample of Model 3 pricing results:\")\n",
        "print(model3_df_results.head())\n",
        "\n",
        "# Merge Model 3 prices back to the main DataFrame\n",
        "df = df.merge(model3_df_results[['Timestamp', 'SystemCodeNumber', 'Model3_Price', 'AvgCompetitorPrice', 'CompetitiveAdvantageFactor']],\n",
        "              on=['Timestamp', 'SystemCodeNumber'],\n",
        "              how='left')\n",
        "print(\"\\nModel 3 prices merged back to main DataFrame.\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# --- Milestone 5: Real-Time Simulation with Pathway Integration (Conceptual Code) ---\n",
        "\n",
        "print(\"\\n\\n--- Milestone 5: Conceptual Code for Pathway Real-Time Simulation ---\")\n",
        "print(\"This section outlines how Pathway would be used for real-time data ingestion and processing.\")\n",
        "print(\"Actual execution requires Pathway installation (`pip install pathway`) and a proper setup.\")\n",
        "print(\"The code below is illustrative and not directly executable without a Pathway environment.\")\n",
        "\n",
        "\"\"\"\n",
        "import pathway as pw\n",
        "\n",
        "# Define your pricing functions to be used within Pathway's map/reduce operations\n",
        "# These functions would operate on Pathway Table rows.\n",
        "\n",
        "# Constants (re-defined for clarity in Pathway context, but ideally passed or globally accessible)\n",
        "# BASE_PRICE, MIN_PRICE_GLOBAL, MAX_PRICE_GLOBAL, ALPHA_MODEL1, etc. would be accessible.\n",
        "\n",
        "def pathway_calculate_model1_price(row, current_price_state):\n",
        "    # In Pathway, state management is explicit. `current_price_state` would be a pw.StateTable\n",
        "    # or similar mechanism. This function would be part of a `pw.map` or `pw.reduce` operation.\n",
        "    lot_id = row.SystemCodeNumber\n",
        "    occupancy_rate = row.OccupancyRate\n",
        "    prev_price = current_price_state.get(lot_id, BASE_PRICE) # Retrieve previous price from state\n",
        "    next_price = prev_price + ALPHA_MODEL1 * occupancy_rate\n",
        "    return max(MIN_PRICE_GLOBAL, min(MAX_PRICE_GLOBAL, next_price))\n",
        "\n",
        "def pathway_calculate_demand(row):\n",
        "    return (\n",
        "        ALPHA_OCCUPANCY * row.OccupancyRate +\n",
        "        ALPHA_QUEUELENGTH * row.QueueLength +\n",
        "        ALPHA_TRAFFIC * row.TrafficConditionEncoded +\n",
        "        ALPHA_SPECIALDAY * row.IsSpecialDay +\n",
        "        ALPHA_VEHICLETYPE * row.VehicleTypeWeight\n",
        "    )\n",
        "\n",
        "def pathway_calculate_model2_price(row):\n",
        "    # Assumes NormalizedDemand is already calculated on the row\n",
        "    price = BASE_PRICE * (1 + LAMBDA_MODEL2 * row.NormalizedDemand)\n",
        "    return max(MIN_PRICE_GLOBAL, min(MAX_PRICE_GLOBAL, price))\n",
        "\n",
        "def pathway_calculate_model3_price(row, competitor_prices_table):\n",
        "    # This is complex. `competitor_prices_table` would be another Pathway table\n",
        "    # containing the latest prices of all lots. This function would involve a join\n",
        "    # operation in Pathway to get competitor prices for the current lot.\n",
        "    lot_id = row.SystemCodeNumber\n",
        "    normalized_demand = row.NormalizedDemand\n",
        "\n",
        "    # Conceptual: Get competitor prices from `competitor_prices_table` based on `distances` matrix\n",
        "    # This would involve a complex join and aggregation in Pathway.\n",
        "    # For illustration, let's assume `row.AvgCompetitorPrice` and `row.CompetitiveAdvantageFactor`\n",
        "    # are already available from a prior Pathway join/computation.\n",
        "    avg_competitor_price = row.AvgCompetitorPrice # From a joined table\n",
        "    competitive_advantage_factor = row.CompetitiveAdvantageFactor # From a joined table\n",
        "\n",
        "    model3_price = BASE_PRICE * (1 + LAMBDA_MODEL2 * normalized_demand + competitive_advantage_factor)\n",
        "    return max(MIN_PRICE_GLOBAL, min(MAX_PRICE_GLOBAL, model3_price))\n",
        "\n",
        "\n",

  
        "print(\"\\nPathway setup involves:\")\n",
        "print(\"- Defining input data streams (e.g., from CSV, Kafka, custom generators).\")\n",
        "print(\"- Applying transformations (`.select`, `.map`, `.filter`) and stateful computations (`.reduce`, `pw.StateTable`).\")\n",
        "print(\"- Managing state for models that depend on previous values (e.g., Model 1, Model 3 for competitor prices).\")\n",
        "print(\"- Defining output sinks (e.g., print to console, write to another database, feed to a visualization tool).\")\n",
        "print(\"Refer to Pathway documentation for detailed API usage for stateful transformations, joins, and deployment.\")\n",
        "\n",
        "\n",
        "# --- Milestone 6: Visualization Implementation (Bokeh) ---\n",
        "\n",
        "print(\"\\n\\n--- Milestone 6: Bokeh Visualization ---\")\n",
        "print(\"These plots demonstrate the pricing behavior using the historical data.\")\n",
        "print(\"In a real-time Pathway application, these Bokeh plots would be continuously updated\")\n",
        "print(\"by streaming data from the Pathway output table to a Bokeh server or directly within a dashboard.\")\n",
        "\n",
        "# 1. Real-time pricing line plots for each parking space\n",
        "print(\"\\n--- Real-time Pricing Line Plots for Each Parking Space (Sample Lots) ---\")\n",
        "\n",
        "# Select a few parking lots to visualize (e.g., first 5 unique lots)\n",
        "sample_lot_ids = df['SystemCodeNumber'].unique()[:5]\n",
        "plot_df_sample_lots = df[df['SystemCodeNumber'].isin(sample_lot_ids)].copy()\n",
        "\n",
        "# Melt the DataFrame to easily plot multiple price models for each lot\n",
        "plot_df_melted_models = plot_df_sample_lots.melt(\n",
        "    id_vars=['Timestamp', 'SystemCodeNumber'],\n",
        "    value_vars=['Model1_Price', 'Model2_Price', 'Model3_Price'],\n",
        "    var_name='Model',\n",
        "    value_name='Price'\n",
        ")\n",
        "\n",
        "# Create a ColumnDataSource for Bokeh (useful for potential live updates)\n",
        "source_model_prices = ColumnDataSource(plot_df_melted_models)\n",
        "\n",
        "# Create the plot figure\n",
        "p_prices = figure(\n",
        "    title=\"Dynamic Pricing Over Time (Sample Lots)\",\n",
        "    x_axis_label=\"Time\",\n",
        "    y_axis_label=\"Price ($)\",\n",
        "    x_axis_type=\"datetime\",\n",
        "    height=450,\n",
        "    width=900,\n",
        "    tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
        "    sizing_mode=\"scale_width\"\n",
        ")\n",
        "\n",
        "# Define colors for different lots (using Category10 palette)\n",
        "unique_lots_in_plot = plot_df_melted_models['SystemCodeNumber'].unique().tolist()\n",
        "colors_for_lots = Category10[len(unique_lots_in_plot)]\n",
        "color_map_lots = {lot: colors_for_lots[i] for i, lot in enumerate(unique_lots_in_plot)}\n",
        "\n",
        "# Add lines for each parking lot and model\n",
        "for i, lot_id in enumerate(unique_lots_in_plot):\n",
        "    lot_data = plot_df_melted_models[plot_df_melted_models['SystemCodeNumber'] == lot_id]\n",
        "    for model_name in ['Model1_Price', 'Model2_Price', 'Model3_Price']:\n",
        "        model_data = lot_data[lot_data['Model'] == model_name]\n",
        "        line_dash_style = 'solid' # Default\n",
        "        if 'Model1' in model_name:\n",
        "            line_dash_style = 'solid'\n",
        "        elif 'Model2' in model_name:\n",
        "            line_dash_style = 'dashed'\n",
        "        elif 'Model3' in model_name:\n",
        "            line_dash_style = 'dotted'\n",
        "\n",
        "        p_prices.line(\n",
        "            x='Timestamp',\n",
        "            y='Price',\n",
        "            source=ColumnDataSource(model_data),\n",
        "            legend_label=f\"{lot_id} - {model_name.replace('_Price', '')}\",\n",
        "            color=color_map_lots[lot_id],\n",
        "            line_dash=line_dash_style,\n",
        "            line_width=2,\n",
        "            alpha=0.7\n",
        "        )\n",
        "\n",
        "p_prices.xaxis.formatter = DatetimeTickFormatter(hours=\"%H:%M\", days=\"%m/%d\", months=\"%m/%Y\")\n",
        "p_prices.legend.location = \"top_left\"\n",
        "p_prices.legend.click_policy = \"hide\" # Allow clicking legend to hide/show lines\n",
        "p_prices.legend.label_text_font_size = \"8pt\" # Adjust font size for better readability if many legends\n",
        "\n",
        "show(p_prices)\n",
        "\n",
        "\n",
        "# 2. Comparison with competitor prices (for a single selected lot)\n",
        "print(\"\\n--- Price Comparison with Competitors (for a selected lot) ---\")\n",
        "\n",
        "# Choose a single lot to focus on for competitor comparison\n",
        "focus_lot_id = df['SystemCodeNumber'].unique()[0] # Example: first unique lot\n",
        "\n",
        "# Identify nearby competitors based on the distance matrix\n",
        "nearby_competitors_for_focus = distances.loc[focus_lot_id][distances.loc[focus_lot_id] <= COMPETITOR_DISTANCE_THRESHOLD_KM].index.tolist()\n",
        "if focus_lot_id in nearby_competitors_for_focus:\n",
        "    nearby_competitors_for_focus.remove(focus_lot_id) # Remove self\n",
        "\n",
        "# Limit to a few competitors for plot clarity if many exist\n",
        "competitor_display_ids = nearby_competitors_for_focus[:3] # Show up to 3 closest competitors\n",
        "\n",
        "if not competitor_display_ids:\n",
        "    print(f\"No nearby competitors found for {focus_lot_id} within {COMPETITOR_DISTANCE_THRESHOLD_KM}km for visualization.\")\n",
        "    print(\"Plotting only the focus lot's price.\")\n",
        "    all_display_lots_comp = [focus_lot_id]\n",
        "else:\n",
        "    print(f\"Displaying prices for {focus_lot_id} and competitors: {competitor_display_ids}\")\n",
        "    all_display_lots_comp = [focus_lot_id] + competitor_display_ids\n",
        "\n",
        "\n",
        "# Prepare data for competitor comparison plot (focus on Model 3 prices)\n",
        "competitor_plot_df = df[df['SystemCodeNumber'].isin(all_display_lots_comp)].copy()\n",
        "\n",
        "# Melt the DataFrame to plot prices for multiple lots\n",
        "competitor_plot_df_melted = competitor_plot_df.melt(\n",
        "    id_vars=['Timestamp', 'SystemCodeNumber'],\n",
        "    value_vars=['Model3_Price'], # Focus on Model 3 price for competitive analysis\n",
        "    var_name='Model',\n",
        "    value_name='Price'\n",
        ")\n",
        "\n",
        "\n",
        "p_competitors = figure(\n",
        "    title=f\"Price Comparison for {focus_lot_id} vs. Competitors (Model 3)\",\n",
        "    x_axis_label=\"Time\",\n",
        "    y_axis_label=\"Price ($)\",\n",
        "    x_axis_type=\"datetime\",\n",
        "    height=450,\n",
        "    width=900,\n",
        "    tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
        "    sizing_mode=\"scale_width\"\n",
        ")\n",
        "\n",
        "# Define colors for the focus lot and its competitors\n",
        "colors_for_comp_plot = Category10[max(3, len(all_display_lots_comp))] # Ensure at least 3 colors\n",
        "comp_color_map = {lot: colors_for_comp_plot[i] for i, lot in enumerate(all_display_lots_comp)}\n",
        "\n",
        "for lot_id in all_display_lots_comp:\n",
        "    lot_data = competitor_plot_df_melted[competitor_plot_df_melted['SystemCodeNumber'] == lot_id]\n",
        "    line_dash = 'solid' if lot_id == focus_lot_id else 'dashed' # Focus lot is solid, competitors are dashed\n",
        "    p_competitors.line(\n",
        "        x='Timestamp',\n",
        "        y='Price',\n",
        "        source=ColumnDataSource(lot_data),\n",
        "        legend_label=f\"{lot_id} Price\",\n",
        "        color=comp_color_map[lot_id],\n",
        "        line_dash=line_dash,\n",
        "        line_width=2,\n",
        "        alpha=0.8\n",
        "    )\n",
        "\n",
        "p_competitors.xaxis.formatter = DatetimeTickFormatter(hours=\"%H:%M\", days=\"%m/%d\", months=\"%m/%Y\")\n",
        "p_competitors.legend.location = \"top_left\"\n",
        "p_competitors.legend.click_policy = \"hide\"\n",
        "p_competitors.legend.label_text_font_size = \"8pt\"\n",
        "\n",
        "show(p_competitors)\n",
        "\n",
        "# 3. Occupancy Rate vs. Price (Example for a single lot)\n",
        "print(\"\\n--- Occupancy Rate vs. Price (Example for a single lot) ---\")\n",
        "\n",
        "# Choose a single lot to visualize\n",
        "occupancy_lot_id = df['SystemCodeNumber'].unique()[1] # Example: second unique lot\n",
        "occupancy_plot_df = df[df['SystemCodeNumber'] == occupancy_lot_id].copy()\n",
        "\n",
        "# Create a ColumnDataSource\n",
        "source_occupancy_price = ColumnDataSource(occupancy_plot_df)\n",
        "\n",
        "p_occupancy = figure(\n",
        "    title=f\"Occupancy Rate vs. Model 3 Price for {occupancy_lot_id}\",\n",
        "    x_axis_label=\"Occupancy Rate\",\n",
        "    y_axis_label=\"Model 3 Price ($)\",\n",
        "    height=400,\n",
        "    width=700,\n",
        "    tools=\"pan,wheel_zoom,box_zoom,reset,save\",\n",
        "    sizing_mode=\"scale_width\"\n",
        ")\n",
        "\n",
        "# Plot scatter points (or a line if ordered by time)\n",
        "p_occupancy.circle(\n",
        "    x='OccupancyRate',\n",
        "    y='Model3_Price',\n",
        "    source=source_occupancy_price,\n",
        "    size=5,\n",
        "    alpha=0.6,\n",
        "    color=\"blue\"\n",
        ")\n",
        "\n",
        "show(p_occupancy)\n",
        "\n",
        "print(\"\\n--- All Visualizations Generated ---\")\n",
        "print(\"Remember to include these visualizations and their interpretations in your final report.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Milestone 1: Data Understanding, Exploration, and Preprocessing ---\n",
            "Loading the dataset 'dataset.csv'...\n",
            "Dataset loaded successfully.\n",
            "\n",
            "--- Initial Data Overview ---\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "   ID SystemCodeNumber  Capacity   Latitude  Longitude  Occupancy VehicleType  \\\n",
            "0   0      BHMBCCMKT01       577  26.144536  91.736172         61         car   \n",
            "1   1      BHMBCCMKT01       577  26.144536  91.736172         64         car   \n",
            "2   2      BHMBCCMKT01       577  26.144536  91.736172         80         car   \n",
            "3   3      BHMBCCMKT01       577  26.144536  91.736172        107         car   \n",
            "4   4      BHMBCCMKT01       577  26.144536  91.736172        150        bike   \n",
            "\n",
            "  TrafficConditionNearby  QueueLength  IsSpecialDay LastUpdatedDate  \\\n",
            "0                    low            1             0      04-10-2016   \n",
            "1                    low            1             0      04-10-2016   \n",
            "2                    low            2             0      04-10-2016   \n",
            "3                    low            2             0      04-10-2016   \n",
            "4                    low            2             0      04-10-2016   \n",
            "\n",
            "  LastUpdatedTime  \n",
            "0        07:59:00  \n",
            "1        08:25:00  \n",
            "2        08:59:00  \n",
            "3        09:32:00  \n",
            "4        09:59:00  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18368 entries, 0 to 18367\n",
            "Data columns (total 12 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   ID                      18368 non-null  int64  \n",
            " 1   SystemCodeNumber        18368 non-null  object \n",
            " 2   Capacity                18368 non-null  int64  \n",
            " 3   Latitude                18368 non-null  float64\n",
            " 4   Longitude               18368 non-null  float64\n",
            " 5   Occupancy               18368 non-null  int64  \n",
            " 6   VehicleType             18368 non-null  object \n",
            " 7   TrafficConditionNearby  18368 non-null  object \n",
            " 8   QueueLength             18368 non-null  int64  \n",
            " 9   IsSpecialDay            18368 non-null  int64  \n",
            " 10  LastUpdatedDate         18368 non-null  object \n",
            " 11  LastUpdatedTime         18368 non-null  object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 1.7+ MB\n",
            "None\n",
            "\n",
            "Descriptive Statistics:\n",
            "                 ID      Capacity      Latitude     Longitude     Occupancy  \\\n",
            "count  18368.000000  18368.000000  18368.000000  18368.000000  18368.000000   \n",
            "mean    9183.500000   1605.214286     25.706547     90.751170    731.084059   \n",
            "std     5302.529208   1131.153886      1.582749      3.536636    621.164982   \n",
            "min        0.000000    387.000000     20.000035     78.000003      2.000000   \n",
            "25%     4591.750000    577.000000     26.140048     91.727995    322.000000   \n",
            "50%     9183.500000   1261.000000     26.147482     91.729511    568.000000   \n",
            "75%    13775.250000   2803.000000     26.147541     91.736172    976.000000   \n",
            "max    18367.000000   3883.000000     26.150504     91.740994   3499.000000   \n",
            "\n",
            "        QueueLength  IsSpecialDay  \n",
            "count  18368.000000  18368.000000  \n",
            "mean       4.587925      0.150915  \n",
            "std        2.580062      0.357975  \n",
            "min        0.000000      0.000000  \n",
            "25%        2.000000      0.000000  \n",
            "50%        4.000000      0.000000  \n",
            "75%        6.000000      0.000000  \n",
            "max       15.000000      1.000000  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "time data \"13-10-2016 07:57:00\" doesn't match format \"%m-%d-%Y %H:%M:%S\", at position 162. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-475781582.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# 3. Combine date and time columns into a single datetime object and sort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LastUpdatedDate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LastUpdatedTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;31m# Sort by timestamp to simulate chronological data flow for pricing models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mixed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_strptime_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     result, tz_parsed = objects_to_datetime64(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0mCall\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0mbehavior\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m'errors'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtz_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: time data \"13-10-2016 07:57:00\" doesn't match format \"%m-%d-%Y %H:%M:%S\", at position 162. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j5C__zWrEa6Z",
        "outputId": "1ce1e578-3579-4a35-da3d-6b151c3afaf7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
